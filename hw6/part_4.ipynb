{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "1TQMUXFiLUpR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Connect to Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths\n",
        "zip_file_location = '/content/cifake_dataset.zip'  # Path to the CIFAKE dataset zip file\n",
        "unzip_location = '/content'  # Destination folder for extracted files\n",
        "\n",
        "# Step 2: Extract the ZIP file (may take some time)\n",
        "with zipfile.ZipFile(zip_file_location, 'r') as zip_file:\n",
        "    zip_file.extractall(unzip_location)"
      ],
      "metadata": {
        "id": "JSY-QIIxMNCk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set up paths for training and validation folders\n",
        "real_train_path = os.path.join(unzip_location, 'cifake_dataset', 'train', 'REAL')\n",
        "fake_train_path = os.path.join(unzip_location, 'cifake_dataset', 'train', 'FAKE')\n",
        "validation_folder_path = os.path.join(unzip_location, 'cifake_dataset', 'validation')\n",
        "real_validation_path = os.path.join(validation_folder_path, 'REAL')\n",
        "fake_validation_path = os.path.join(validation_folder_path, 'FAKE')\n",
        "\n",
        "# Create validation folders if they do not exist\n",
        "os.makedirs(real_validation_path, exist_ok=True)\n",
        "os.makedirs(fake_validation_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "XZlTP6SiMPVx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Transfer 10,000 images from train/REAL to validation/REAL and from train/FAKE to validation/FAKE\n",
        "def transfer_images(source_folder, destination_folder, count):\n",
        "    image_list = os.listdir(source_folder)\n",
        "    random.shuffle(image_list)  # Shuffle images for random selection\n",
        "    for image in image_list[:count]:\n",
        "        source_image_path = os.path.join(source_folder, image)\n",
        "        destination_image_path = os.path.join(destination_folder, image)\n",
        "        shutil.move(source_image_path, destination_image_path)\n",
        "\n",
        "# Move images\n",
        "transfer_images(real_train_path, real_validation_path, 10000)\n",
        "transfer_images(fake_train_path, fake_validation_path, 10000)"
      ],
      "metadata": {
        "id": "Amo_UlpGMYm8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2**"
      ],
      "metadata": {
        "id": "0DCy_EUNEvOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Load datasets from the directories\n",
        "train_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'train'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'validation'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'test'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrQGL6A8UmOn",
        "outputId": "2dda5529-85d5-474e-9252-6f1de2b1431a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80000 files belonging to 2 classes.\n",
            "Found 35989 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the enhanced CNN model with Batch Normalization and more layers\n",
        "model = models.Sequential([\n",
        "    # Rescaling layer\n",
        "    layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
        "\n",
        "    # First Conv2D layer with ReLU activation, Batch Normalization, and Max Pooling\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Conv2D layer with increased filters, Batch Normalization, and Max Pooling\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third Conv2D layer for deeper features, Batch Normalization, and Max Pooling\n",
        "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the output for the dense layers\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # First Dense layer with ReLU activation and Dropout\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    # Second Dense layer with ReLU activation and Dropout\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WFTGzirE6vk",
        "outputId": "307462b0-bfb9-4c36-8993-a1a0ea6c3f15"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define ModelCheckpoint callback to save the best model\n",
        "checkpoint_cb = ModelCheckpoint(\"best_custom_model.keras\", save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Train the model for 30 epochs\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=[checkpoint_cb])\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3h-iwhE_u2",
        "outputId": "e7e20c43-33ad-4adb-fa7b-7aaccd25990f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - accuracy: 0.8464 - loss: 0.3709 - val_accuracy: 0.9175 - val_loss: 0.2059\n",
            "Epoch 2/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9202 - loss: 0.2051 - val_accuracy: 0.9419 - val_loss: 0.1556\n",
            "Epoch 3/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.1824 - val_accuracy: 0.9493 - val_loss: 0.1365\n",
            "Epoch 4/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9396 - loss: 0.1591 - val_accuracy: 0.9495 - val_loss: 0.1288\n",
            "Epoch 5/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9461 - loss: 0.1442 - val_accuracy: 0.8863 - val_loss: 0.3071\n",
            "Epoch 6/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.9530 - loss: 0.1242 - val_accuracy: 0.9457 - val_loss: 0.1401\n",
            "Epoch 7/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.1099 - val_accuracy: 0.9622 - val_loss: 0.1009\n",
            "Epoch 8/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.9657 - loss: 0.0923 - val_accuracy: 0.9498 - val_loss: 0.1285\n",
            "Epoch 9/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.0799 - val_accuracy: 0.9548 - val_loss: 0.1297\n",
            "Epoch 10/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9729 - loss: 0.0733 - val_accuracy: 0.9170 - val_loss: 0.2870\n",
            "Epoch 11/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9763 - loss: 0.0638 - val_accuracy: 0.9723 - val_loss: 0.0821\n",
            "Epoch 12/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0570 - val_accuracy: 0.9684 - val_loss: 0.0934\n",
            "Epoch 13/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0495 - val_accuracy: 0.9622 - val_loss: 0.1068\n",
            "Epoch 14/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.0484 - val_accuracy: 0.9700 - val_loss: 0.0915\n",
            "Epoch 15/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0439 - val_accuracy: 0.9686 - val_loss: 0.1007\n",
            "Epoch 16/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0424 - val_accuracy: 0.9644 - val_loss: 0.1172\n",
            "Epoch 17/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0361 - val_accuracy: 0.9665 - val_loss: 0.1092\n",
            "Epoch 18/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0460 - val_accuracy: 0.9719 - val_loss: 0.0829\n",
            "Epoch 19/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0239 - val_accuracy: 0.9694 - val_loss: 0.0960\n",
            "Epoch 20/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0350 - val_accuracy: 0.9626 - val_loss: 0.1414\n",
            "Epoch 21/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0226 - val_accuracy: 0.9674 - val_loss: 0.1231\n",
            "Epoch 22/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0231 - val_accuracy: 0.9703 - val_loss: 0.1078\n",
            "Epoch 23/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0311 - val_accuracy: 0.9740 - val_loss: 0.0968\n",
            "Epoch 24/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0193 - val_accuracy: 0.9763 - val_loss: 0.0884\n",
            "Epoch 25/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0241 - val_accuracy: 0.9730 - val_loss: 0.0911\n",
            "Epoch 26/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0190 - val_accuracy: 0.9744 - val_loss: 0.1028\n",
            "Epoch 27/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0202 - val_accuracy: 0.9587 - val_loss: 0.1699\n",
            "Epoch 28/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0177 - val_accuracy: 0.9709 - val_loss: 0.1073\n",
            "Epoch 29/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0177 - val_accuracy: 0.9712 - val_loss: 0.1075\n",
            "Epoch 30/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0153 - val_accuracy: 0.9763 - val_loss: 0.0934\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1622\n",
            "Test Accuracy: 95.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTuJdvJo_3hD",
        "outputId": "ef11d70d-7b71-4895-b2dc-11ad57ac3c96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1640\n",
            "Test Accuracy: 95.76%\n"
          ]
        }
      ]
    }
  ]
}