{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "from transformers import AutoModelForImageClassification, AutoProcessor\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# # Step 1: Connect to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths\n",
        "zip_path = '/content/drive/MyDrive/cifake_dataset.zip'  # Path to the dataset zip file\n",
        "unzip_location = '/content/data'  # Destination folder for extracted files\n",
        "\n",
        "# Step 2: Extract the ZIP file (may take some time)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_location)\n",
        "\n",
        "# Step 3: Set up paths for training and validation folders\n",
        "train_real_src = '/content/train/REAL'\n",
        "train_fake_src = '/content/train/FAKE'\n",
        "validation_real_dst = '/content/validation/REAL'\n",
        "validation_fake_dst = '/content/validation/FAKE'\n",
        "\n",
        "# Create validation folders if they do not exist\n",
        "os.makedirs(validation_real_dst, exist_ok=True)\n",
        "os.makedirs(validation_fake_dst, exist_ok=True)\n",
        "\n",
        "# Step 4: Transfer images from train/REAL to validation/REAL and from train/FAKE to validation/FAKE\n",
        "real_images = os.listdir(train_real_src)\n",
        "for img in tqdm(real_images[:10000], desc=\"Transferring REAL images to validation\"):\n",
        "    shutil.move(os.path.join(train_real_src, img), validation_real_dst)\n",
        "\n",
        "fake_images = os.listdir(train_fake_src)\n",
        "for img in tqdm(fake_images[:10000], desc=\"Transferring FAKE images to validation\"):\n",
        "    shutil.move(os.path.join(train_fake_src, img), validation_fake_dst)"
      ],
      "metadata": {
        "id": "BHLoc3223mDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for testing images\n",
        "real_test_path = '/content/test/REAL'\n",
        "fake_test_path = '/content/test/FAKE'\n",
        "\n",
        "# Step 5: Load the image classifier model from Hugging Face\n",
        "model_identifier = \"Organika/sdxl-detector\"\n",
        "classifier_model = AutoModelForImageClassification.from_pretrained(model_identifier).to(device)\n",
        "preprocess = AutoProcessor.from_pretrained(model_identifier)"
      ],
      "metadata": {
        "id": "H2-mealG3pSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfxeX936zcXW",
        "outputId": "34477799-c2e0-4456-c58e-8d1137522658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Transferring REAL images to validation: 100%|██████████| 10000/10000 [00:00<00:00, 28158.03it/s]\n",
            "Transferring FAKE images to validation: 100%|██████████| 10000/10000 [00:00<00:00, 27118.76it/s]\n",
            "Calculating accuracy: 100%|██████████| 625/625 [02:29<00:00,  4.19it/s]\n",
            "Calculating accuracy: 100%|██████████| 625/625 [02:30<00:00,  4.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for REAL images (predicted as 'human'): 87.14%\n",
            "Accuracy for FAKE images (predicted as 'artificial'): 27.68%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Custom Dataset Class\n",
        "def collate_fn(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    images = torch.cat(images, dim=0)\n",
        "    return images, labels\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_folder, preprocess):\n",
        "        if not os.path.exists(image_folder):\n",
        "            raise FileNotFoundError(f\"Image folder {image_folder} does not exist.\")\n",
        "        self.image_folder = image_folder\n",
        "        self.image_files = os.listdir(image_folder)\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_folder, self.image_files[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        inputs = self.preprocess(images=img, return_tensors=\"pt\")\n",
        "        return inputs['pixel_values'], self.image_files[idx]\n",
        "\n",
        "# Define function to classify images and calculate accuracy\n",
        "def calculate_accuracy(dataset, expected_label, batch_size=16):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "    correct_count = 0\n",
        "    total_images = len(dataset)\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=\"Calculating accuracy\"):\n",
        "        images, labels = batch\n",
        "        images = images.to(device)\n",
        "        with torch.no_grad():\n",
        "            output_logits = classifier_model(pixel_values=images)\n",
        "        predicted_idx = torch.argmax(output_logits.logits, dim=-1)\n",
        "        for idx in predicted_idx:\n",
        "            predicted_label = classifier_model.config.id2label[idx.item()]\n",
        "            if predicted_label == expected_label:\n",
        "                correct_count += 1\n",
        "\n",
        "    accuracy_percentage = (correct_count / total_images) * 100\n",
        "    return accuracy_percentage\n",
        "\n",
        "# Step 6: Calculate detection accuracy for REAL and FAKE images\n",
        "try:\n",
        "    real_dataset = ImageDataset(real_test_path, preprocess)\n",
        "    fake_dataset = ImageDataset(fake_test_path, preprocess)\n",
        "\n",
        "    accuracy_real = calculate_accuracy(real_dataset, \"human\")  # Assuming 'human' is the label for real images\n",
        "    accuracy_fake = calculate_accuracy(fake_dataset, \"artificial\")  # Assuming 'artificial' is the label for fake images\n",
        "\n",
        "    # Display results\n",
        "    print(f\"Accuracy for REAL images (predicted as 'human'): {accuracy_real:.2f}%\")\n",
        "    print(f\"Accuracy for FAKE images (predicted as 'artificial'): {accuracy_fake:.2f}%\")\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}