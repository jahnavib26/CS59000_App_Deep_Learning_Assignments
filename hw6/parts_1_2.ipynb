{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "metadata": {
        "id": "1TQMUXFiLUpR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Connect to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths\n",
        "zip_file_location = '/content/drive/MyDrive/cifake_dataset.zip'  # Path to the CIFAKE dataset zip file\n",
        "unzip_location = '/content/data'  # Destination folder for extracted files\n",
        "\n",
        "# Step 2: Extract the ZIP file (may take some time)\n",
        "with zipfile.ZipFile(zip_file_location, 'r') as zip_file:\n",
        "    zip_file.extractall(unzip_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSY-QIIxMNCk",
        "outputId": "ee7a0807-9bbc-4a6a-99ec-132cc558b26b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Set up paths for training and validation folders\n",
        "real_train_path = os.path.join(unzip_location, 'cifake_dataset', 'train', 'REAL')\n",
        "fake_train_path = os.path.join(unzip_location, 'cifake_dataset', 'train', 'FAKE')\n",
        "validation_folder_path = os.path.join(unzip_location, 'cifake_dataset', 'validation')\n",
        "real_validation_path = os.path.join(validation_folder_path, 'REAL')\n",
        "fake_validation_path = os.path.join(validation_folder_path, 'FAKE')\n",
        "\n",
        "# Create validation folders if they do not exist\n",
        "os.makedirs(real_validation_path, exist_ok=True)\n",
        "os.makedirs(fake_validation_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "XZlTP6SiMPVx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Transfer 10,000 images from train/REAL to validation/REAL and from train/FAKE to validation/FAKE\n",
        "def transfer_images(source_folder, destination_folder, count):\n",
        "    image_list = os.listdir(source_folder)\n",
        "    random.shuffle(image_list)  # Shuffle images for random selection\n",
        "    for image in image_list[:count]:\n",
        "        source_image_path = os.path.join(source_folder, image)\n",
        "        destination_image_path = os.path.join(destination_folder, image)\n",
        "        shutil.move(source_image_path, destination_image_path)\n",
        "\n",
        "# Move images\n",
        "transfer_images(real_train_path, real_validation_path, 10000)\n",
        "transfer_images(fake_train_path, fake_validation_path, 10000)"
      ],
      "metadata": {
        "id": "Amo_UlpGMYm8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2**"
      ],
      "metadata": {
        "id": "0DCy_EUNEvOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Load datasets from the directories\n",
        "train_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'train'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'validation'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n",
        "\n",
        "test_ds = image_dataset_from_directory(\n",
        "    os.path.join(unzip_location, 'cifake_dataset', 'test'),\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrQGL6A8UmOn",
        "outputId": "0a0c71e2-d08f-4552-90b8-902aca63ad79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model based on the architecture\n",
        "model = models.Sequential([\n",
        "    # Rescaling layer\n",
        "    layers.Rescaling(1.0 / 255, input_shape=(32, 32, 3)),\n",
        "\n",
        "    # First Conv2D layer with ReLU activation, followed by Max Pooling\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Conv2D layer with ReLU activation, followed by Max Pooling\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the output and add Dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WFTGzirE6vk",
        "outputId": "41333d5f-c97e-4b16-9ec5-7f2bc3351cee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define ModelCheckpoint callback to save the best model\n",
        "checkpoint_cb = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_loss\")\n",
        "\n",
        "# Train the model for 30 epochs\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=[checkpoint_cb])\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb3h-iwhE_u2",
        "outputId": "6635e668-bdd3-40b4-babb-a355243c4375"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.4385 - val_accuracy: 0.8861 - val_loss: 0.2725\n",
            "Epoch 2/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.2541 - val_accuracy: 0.9119 - val_loss: 0.2232\n",
            "Epoch 3/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2167 - val_accuracy: 0.9212 - val_loss: 0.2002\n",
            "Epoch 4/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.1904 - val_accuracy: 0.9241 - val_loss: 0.1900\n",
            "Epoch 5/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9308 - loss: 0.1734 - val_accuracy: 0.9280 - val_loss: 0.1812\n",
            "Epoch 6/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.1595 - val_accuracy: 0.9280 - val_loss: 0.1847\n",
            "Epoch 7/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.1469 - val_accuracy: 0.9136 - val_loss: 0.2267\n",
            "Epoch 8/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1303 - val_accuracy: 0.9284 - val_loss: 0.1880\n",
            "Epoch 9/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9526 - loss: 0.1202 - val_accuracy: 0.9282 - val_loss: 0.1886\n",
            "Epoch 10/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.1133 - val_accuracy: 0.9258 - val_loss: 0.1980\n",
            "Epoch 11/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1024 - val_accuracy: 0.9229 - val_loss: 0.2174\n",
            "Epoch 12/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9638 - loss: 0.0947 - val_accuracy: 0.9293 - val_loss: 0.2029\n",
            "Epoch 13/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9665 - loss: 0.0850 - val_accuracy: 0.9226 - val_loss: 0.2268\n",
            "Epoch 14/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.0797 - val_accuracy: 0.9265 - val_loss: 0.2336\n",
            "Epoch 15/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9713 - loss: 0.0742 - val_accuracy: 0.9282 - val_loss: 0.2455\n",
            "Epoch 16/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.0644 - val_accuracy: 0.9300 - val_loss: 0.2289\n",
            "Epoch 17/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0592 - val_accuracy: 0.9241 - val_loss: 0.2810\n",
            "Epoch 18/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0607 - val_accuracy: 0.9251 - val_loss: 0.2885\n",
            "Epoch 19/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0537 - val_accuracy: 0.9271 - val_loss: 0.2881\n",
            "Epoch 20/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0474 - val_accuracy: 0.9245 - val_loss: 0.3090\n",
            "Epoch 21/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0416 - val_accuracy: 0.9184 - val_loss: 0.3830\n",
            "Epoch 22/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.0430 - val_accuracy: 0.9290 - val_loss: 0.3299\n",
            "Epoch 23/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0400 - val_accuracy: 0.9234 - val_loss: 0.3533\n",
            "Epoch 24/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0375 - val_accuracy: 0.9246 - val_loss: 0.3575\n",
            "Epoch 25/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.9868 - loss: 0.0345 - val_accuracy: 0.9244 - val_loss: 0.3625\n",
            "Epoch 26/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0396 - val_accuracy: 0.9262 - val_loss: 0.3933\n",
            "Epoch 27/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0336 - val_accuracy: 0.9273 - val_loss: 0.3896\n",
            "Epoch 28/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0347 - val_accuracy: 0.9251 - val_loss: 0.4203\n",
            "Epoch 29/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9897 - loss: 0.0287 - val_accuracy: 0.9198 - val_loss: 0.4123\n",
            "Epoch 30/30\n",
            "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0275 - val_accuracy: 0.9245 - val_loss: 0.4427\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.4413\n",
            "Test Accuracy: 92.15%\n"
          ]
        }
      ]
    }
  ]
}